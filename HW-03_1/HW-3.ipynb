{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-7. Прогнозирование биологического ответа HW-3.2 \n",
    "\n",
    "Необходимо обучить две модели: логистическую регрессию и случайный лес. Далее нужно сделать подбор гиперпараметров с помощью базовых и продвинутых методов оптимизации. Важно использовать все четыре метода (GridSeachCV, RandomizedSearchCV, Hyperopt, Optuna) хотя бы по разу, максимальное количество итераций не должно превышать 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold, cross_validate, cross_val_score\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3751 entries, 0 to 3750\n",
      "Columns: 1777 entries, Activity to D1776\n",
      "dtypes: float64(942), int64(835)\n",
      "memory usage: 50.9 MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/_train_sem09.csv\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.drop(\"Activity\", axis=1), data[\"Activity\"]\n",
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала подберем параметры и одучим линейные модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.91 s\n",
      "Wall time: 4min 39s\n",
      "RandomizedSearchCV: Наилучшие значения гиперпараметров {'solver': 'saga', 'penalty': 'l1', 'C': 1}\n",
      "CPU times: total: 7.14 s\n",
      "Wall time: 6min 17s\n",
      "GridSearchCV: Наилучшие значения гиперпараметров {'C': 1, 'penalty': 'l1', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "paramgrid_log = [{\"penalty\": ['l2'], \"solver\": ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'], \"C\":  range(1, 10)},\n",
    "                 {\"penalty\": ['l1'], \"solver\": ['liblinear', 'saga'], \"C\":  range(1, 10)}\n",
    "                 ]\n",
    "\n",
    "# подбор с помощью RandomizedSearchCV\n",
    "random = RandomizedSearchCV(\n",
    "    estimator= LogisticRegression(random_state=random_state, n_jobs=-1, max_iter=50),\n",
    "    param_distributions=paramgrid_log,\n",
    "    cv=kf,\n",
    "    n_iter=50,\n",
    "    n_jobs=-1,\n",
    "    random_state=random_state\n",
    ")\n",
    "%time random.fit(X,y)\n",
    "score_random = cross_val_score(random.best_estimator_, X, y, cv=kf, scoring=\"f1\", n_jobs=-1).mean()\n",
    "print(\"RandomizedSearchCV: Наилучшие значения гиперпараметров {}\".format(random.best_params_))\n",
    "\n",
    "# подбор с помощью GridSearchCV\n",
    "grid = GridSearchCV(\n",
    "    estimator= LogisticRegression(random_state=random_state, n_jobs=-1, max_iter=50),\n",
    "    param_grid=paramgrid_log,\n",
    "    cv=kf,\n",
    "    n_jobs=-1\n",
    ")\n",
    "%time grid.fit(X,y)\n",
    "score_grid = cross_val_score(grid.best_estimator_, X, y, cv=kf, scoring=\"f1\", n_jobs=-1).mean()\n",
    "print(\"GridSearchCV: Наилучшие значения гиперпараметров {}\".format(grid.best_params_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно видеть, random search нашел теже параметры, но быстрее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем параметры с помощью optuna и hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525664c31cb5455d8e8815b006023b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 1s\n",
      "Wall time: 3min 29s\n",
      "Наилучшие значения гиперпараметров {'penalty': 'l1', 'C': 1, 'solver_l1': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "# подбор с помощью optuna\n",
    "def optuna_rf(trial):\n",
    "    # задаем пространства поиска гиперпараметров\n",
    "    penalty = trial.suggest_categorical('penalty', ['l2', 'l1'])\n",
    "    \n",
    "    C = trial.suggest_int('C', 1, 10, 1)\n",
    "\n",
    "    if penalty == 'l2':\n",
    "        solver = trial.suggest_categorical('solver_l2', ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'])\n",
    "    else:\n",
    "       solver = trial.suggest_categorical('solver_l1', [ 'liblinear','saga'])     \n",
    "    # создаем модель\n",
    "    model = LogisticRegression(random_state=random_state, n_jobs=-1, max_iter=50, solver=solver, penalty=penalty, C=C)\n",
    "    # обучаем модель\n",
    "    model.fit(X, y)\n",
    "\n",
    "    score = cross_val_score(model, X, y, cv=kf, scoring=\"f1\", n_jobs=-1).mean()\n",
    "    return score\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=\"LogisticRegression\", direction=\"maximize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "%time study.optimize(optuna_rf, n_trials=20, show_progress_bar=True)\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(study.best_params))\n",
    "\n",
    "# преобразуем словарь так чтобы избавиться от solver_l1 и solver_l2\n",
    "if study.best_params.get('solver_l1'):\n",
    "    best_params= study.best_params\n",
    "    best_params[\"solver\"] = best_params.pop(\"solver_l1\")\n",
    "else:\n",
    "    best_params= study.best_params\n",
    "    best_params[\"solver\"] = best_params.pop(\"solver_l2\")\n",
    "model = LogisticRegression(**best_params,random_state=random_state, max_iter=50, n_jobs=-1)\n",
    "score_optuna = cross_val_score(model, X, y, cv=kf, scoring=\"f1\", n_jobs=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [08:17<00:00,  9.94s/trial, best loss: -0.7879869198492568]\n",
      "Наилучшие значения гиперпараметров {'C': 1.0, 'params': 0, 'penalty1': 0, 'solver1': 1}\n"
     ]
    }
   ],
   "source": [
    "# подбор с помощью hyperopt\n",
    "#params необходимо для задания комбинаций, тк например sag не рабоает с l1\n",
    "space = {'C': hp.quniform('C', 1, 10, 1),\n",
    "         'params': hp.choice('params', [{\"penalty\": hp.choice('penalty1', ['l1']),\n",
    "                                         \"solver\": hp.choice('solver1', ['liblinear', 'saga'])},\n",
    "                                        {\"penalty\": hp.choice('penalty2', ['l2']),\n",
    "                                         \"solver\": hp.choice('solver2', ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'])}]),\n",
    "         }\n",
    "\n",
    "\n",
    "def hyperopt_rf(params, cv=kf, X=X, y=y, random_state=random_state):\n",
    "    # функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {'C': int(params['C']),\n",
    "              'penalty': params['params'][\"penalty\"],\n",
    "              'solver': params['params'][\"solver\"]\n",
    "              }\n",
    "    model = LogisticRegression(**params, random_state=random_state, max_iter=50)\n",
    "    model.fit(X, y)\n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    return -score\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(hyperopt_rf,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials,\n",
    "            rstate=np.random.default_rng(random_state)\n",
    "            )\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(best))\n",
    "\n",
    "# преобразуем результат функции в словарь\n",
    "penalty = ['l1','l2']\n",
    "solver1 = ['liblinear', 'saga']\n",
    "solver2 = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "if best[\"params\"]==0:\n",
    "    params = {'C': best[\"C\"], \"solver\": solver1[best[\"solver1\"]], \"penalty\": penalty[best[\"penalty1\"]]}\n",
    "else:\n",
    "    params = {'C': best[\"C\"], \"solver\": solver2[best[\"solver2\"]], \"penalty\": penalty[best[\"penalty2\"]]}\n",
    "    \n",
    "model = LogisticRegression(\n",
    "    **params,\n",
    "    random_state=random_state, \n",
    "    max_iter=50\n",
    ")\n",
    "score_hyperopt = cross_val_score(\n",
    "    model, X, y, cv=kf, scoring=\"f1\", n_jobs=-1).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сравним метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 метрика для GridSearchCV 0.7879869198492568\n",
      "f1 метрика для RandomizedSearchCV 0.7879869198492568\n",
      "f1 метрика для optuna 0.7879869198492568\n",
      "f1 метрика для hyperopt 0.7879869198492568\n"
     ]
    }
   ],
   "source": [
    "print(f\"f1 метрика для GridSearchCV {score_grid}\")\n",
    "print(f\"f1 метрика для RandomizedSearchCV {score_random}\")\n",
    "print(f\"f1 метрика для optuna {score_optuna}\")\n",
    "print(f\"f1 метрика для hyperopt {score_hyperopt}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все метрики одинаковы, тк из за небольшой сетки все алгоритмы нашли одни и теже параметры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучим случайный лес (для RandomizedSearchCV и GridSearchCV сетка меньше)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.8 s\n",
      "Wall time: 3min 6s\n",
      "RandomizedSearchCV: Наилучшие значения гиперпараметров {'n_estimators': 220, 'min_samples_leaf': 2, 'max_depth': 12}\n",
      "CPU times: total: 7.73 s\n",
      "Wall time: 9min 23s\n",
      "GridSearchCV: Наилучшие значения гиперпараметров {'max_depth': 12, 'min_samples_leaf': 2, 'n_estimators': 220}\n"
     ]
    }
   ],
   "source": [
    "paramgrid_log = [{\"n_estimators\": range(100, 300, 60),\n",
    "                  \"max_depth\": range(5, 13, 1),\n",
    "                  \"min_samples_leaf\": range(2, 7, 1)}\n",
    "                 ]\n",
    "\n",
    "# подбор с помощью RandomizedSearchCV\n",
    "random = RandomizedSearchCV(\n",
    "    estimator= RandomForestClassifier(random_state=random_state, n_jobs=-1),\n",
    "    param_distributions=paramgrid_log,\n",
    "    cv=kf,\n",
    "    n_iter=50,\n",
    "    n_jobs=-1,\n",
    "    random_state=random_state\n",
    ")\n",
    "%time random.fit(X,y)\n",
    "score_random = cross_val_score(random.best_estimator_, X, y, cv=kf, scoring=\"f1\", n_jobs=-1).mean()\n",
    "print(\"RandomizedSearchCV: Наилучшие значения гиперпараметров {}\".format(random.best_params_))\n",
    "\n",
    "# подбор с помощью GridSearchCV\n",
    "grid = GridSearchCV(\n",
    "    estimator= RandomForestClassifier(random_state=random_state, n_jobs=-1),\n",
    "    param_grid=paramgrid_log,\n",
    "    cv=kf,\n",
    "    n_jobs=-1\n",
    ")\n",
    "%time grid.fit(X,y)\n",
    "score_grid = cross_val_score(grid.best_estimator_, X, y, cv=kf, scoring=\"f1\", n_jobs=-1).mean()\n",
    "print(\"GridSearchCV: Наилучшие значения гиперпараметров {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для hyperopt и optuna сетка в разы больше, тк не хотелось, чтобы grid часами работал "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь подберем параметры для леса с помощью hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:41<00:00,  9.24s/trial, best loss: -0.8220425766820691]\n",
      "Наилучшие значения гиперпараметров {'max_depth': 25.0, 'min_samples_leaf': 2.0, 'n_estimators': 131.0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "space = {'n_estimators': hp.quniform('n_estimators', 100, 300, 1),\n",
    "         'max_depth': hp.quniform('max_depth', 5, 26, 1),\n",
    "         'min_samples_leaf': hp.quniform('min_samples_leaf', 2, 10, 1),\n",
    "         'max_features': ['sqrt', 'log2']\n",
    "         }\n",
    "\n",
    "\n",
    "def hyperopt_rf(params, cv=kf, X=X, y=y, random_state=random_state):\n",
    "    # функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {'n_estimators': int(params['n_estimators']),\n",
    "              'max_depth': int(params['max_depth']),\n",
    "              'min_samples_leaf': int(params['min_samples_leaf'])\n",
    "              }\n",
    "    model = RandomForestClassifier(**params, random_state=random_state)\n",
    "    model.fit(X, y)\n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    return -score\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(hyperopt_rf,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials,\n",
    "            rstate=np.random.default_rng(random_state)\n",
    "            )\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(best))\n",
    "model = RandomForestClassifier(\n",
    "    random_state=random_state, \n",
    "    n_estimators=int(best['n_estimators']),\n",
    "    max_depth=int(best['max_depth']),\n",
    "    min_samples_leaf=int(best['min_samples_leaf'])\n",
    ")\n",
    "score_hyperopt = cross_val_score(model, X, y, cv=kf, scoring=\"f1\", n_jobs=-1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И с помощью optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d25a39c0336047058640f5280d306631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров {'n_estimators': 237, 'max_depth': 23, 'min_samples_leaf': 2}\n"
     ]
    }
   ],
   "source": [
    "def optuna_rf(trial):\n",
    "    # задаем пространства поиска гиперпараметров\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 300, 1)\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 26, 1)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
    "\n",
    "    # создаем модель\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                   max_depth=max_depth,\n",
    "                                   min_samples_leaf=min_samples_leaf,\n",
    "                                   random_state=random_state)\n",
    "    # обучаем модель\n",
    "    model.fit(X, y)\n",
    "\n",
    "    score = cross_val_score(model, X, y, cv=kf, scoring=\"f1\", n_jobs=-1).mean()\n",
    "    return score\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=\"RandomForestClassifier\", direction=\"maximize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study.optimize(optuna_rf, n_trials=50, show_progress_bar=True)\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(study.best_params))\n",
    "model = RandomForestClassifier(**study.best_params,random_state=random_state)\n",
    "score_optuna = cross_val_score(model, X, y, cv=kf, scoring=\"f1\", n_jobs=-1).mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 метрика для GridSearchCV 0.8189987020859875\n",
      "f1 метрика для RandomizedSearchCV 0.8189987020859875\n",
      "f1 метрика для optuna 0.8240513432365202\n",
      "f1 метрика для hyperopt 0.8220425766820691\n"
     ]
    }
   ],
   "source": [
    "print(f\"f1 метрика для GridSearchCV {score_grid}\")\n",
    "print(f\"f1 метрика для RandomizedSearchCV {score_random}\")\n",
    "print(f\"f1 метрика для optuna {score_optuna}\")\n",
    "print(f\"f1 метрика для hyperopt {score_hyperopt}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лично мне больше понравилась работа с optuna, постараюсь ее чаще использовать в дальнейшем (если конечно нужно перебрать небольшое количесво вариантов, будет целесообразнее использовать GridSearchCV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
